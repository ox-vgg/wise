# Grammar of Audiovisual Search

Audiovisual search is the process of searching a collection of images,
audio and video using a search engine capable of searching through the
visual content in images and video as well as the audible content in
video and audio. Such a search engine can be queried using text in
natural language or any audiovisual content as a search
query. Furthermore, the search operation can also take into account
the text metadata (e.g. year) associated with each audiovisual
content.

In this document, we develop a grammar that enables specification of
search query for any audiovisual search engine. The grammar for
audiovisual search is defined using the [syntax
diagram](https://en.wikipedia.org/wiki/Syntax_diagram) shown below.

<figure>
  <img src="assets/audiovisual-search-syntax-diagram.svg">

  <figcaption>Figure 1: Syntax diagram defining the grammar of
  audiovisual search. To generate a sentence using this grammar,
  we traverse a path from left to right. For example, a straight
  path would generate the sentence <code>Query-Text IN VIDEO</code>
  while a slight detour near <code>NOT</code> would
  generate <code>Query-Text NOT IN VIDEO</code>.</figcaption>

</figure>

Here is a description of the components shown in this syntax diagram.

 * **Query-Text** : corresponds to search query description in a natural language (e.g. animals)
 * **Media-File** : a media filename (e.g. `@cat.jpg`, `@dog-barking.mp3`, etc.) depicting the search query
 * **+** : the plus operator which performs addition of feature vector in the embedding space
 * **-** : the minus operator which performs substraction of feature vector in the embedding space
 * **IN** : specifies the search target which can be audio, video or text metadata
 * **NOT** : prefix that can be applied to `IN` for discarding all results obtained with the `IN` operator
 * **AUDIO/VIDEO/METADATA** : search target where VIDEO corresponds to video frames, AUDIO corresponds to audio channel of videos and METADATA corresponds to text metadata associated with audiovisual assets
 * **AND/OR** : logical operators for merging results from two or more search query specification using the AND/OR logical operation

Sentences adhering to the grammar of audiovisual search can be
generated by traversing a path from the point shown in left hand side
of the syntax diagram shown in Figure 1 and terminating at the points
shown on the right hand side. For example, a path along the stright
line will generate the sentence `Query-Text IN VIDEO` whereas a slight
detour near the `NOT` unit would generate `Query-Text NOT IN
VIDEO`. More complex sentences can be generated by traversing a more
convoluted path in this syntax diagram. The set of all possible path
that can be traversed in this syntax diagram corresponds to the set of
all possible sentences generated by this grammar which in turn defined
the language of audiovisual search.

## Example Sentences Generated by the Audiovisual Grammar

Here are some example sentences generated using the audiovisual

### 1. `cooking IN VIDEO`

Finds all audiovisual assets that show the act of cooking in the
visual stream (e.g. image or video frames)

### 2. `car NOT IN METADATA`

Often, audiovisual assets (e.g. images, audio and videos) are manually
tagged with keywords like "singing", "cooking", "red car" etc. to
describe the content of such assets. Such text description of
audiovisual content is called metadata. This search query finds all
audiovisual assets that depict a car (e.g. picture of a car or sound
produced by a car) but these assets have not been tagged with the text
keyword `car`. Such search queries are useful for locating media
assets with missing or incorrect metadata.

### 3. `"cooking" in VIDEO AND "music" in AUDIO`

Finds all audiovisual assets that show the act of cooking in the
visual stream (e.g. image or video frames) and contains music in the
audio stream (e.g. audio channel of video).

### 4. `cooking IN VIDEO AND music IN AUDIO AND singing NOT IN metadata`

This search query will retrieve all audiovisual assets that show
cooking and contain music but has not been tagged with "singing"
metadata.

### 5. `@dog.jpg + "in snow" IN IMAGE`

The `+` (plus) operator is applied to feature vectors (or embeddings)
corresponding to the image file `dog.jpg` (i.e. Media-File) and text
query `in snow` (i.e. Query-Text) to obtain the feature vector to
retrieve all images that shows a dog in snow. This is an example of
search image collection using a combination of image and text as
search query.

### 6. `animal - @cat.jpg IN VIDEO`

The `-` (minus) operator is applied to feature vectors (or embeddings)
corresponding to the text query `animal` and image file `cat.jpg` to
obtain the feature vector to retrieve all videos showing various types
of animals **except** cats.

### 7. `loud IN VIDEO`

The concept of loudness is easy to understand when considering audio
content.  However, how is this concept depicted in visual medium? An
audiovisual search engine operating on a large scale collection of
videos can help us get an answer to this question using this search
query.
